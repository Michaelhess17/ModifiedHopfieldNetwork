{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-baae88f67fa5>, line 133)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-baae88f67fa5>\"\u001b[1;36m, line \u001b[1;32m133\u001b[0m\n\u001b[1;33m    for\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import hdnet.hopfield as hdn\n",
    "import os\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "import scipy.io as spio\n",
    "\n",
    "class ModifiedHopfieldNet():\n",
    "    \n",
    "    def __init__(self, N, in_directory, out_directory=None, splits=3, train_percent=0.66, num_nets=5, exp_type='J'):\n",
    "        self.N = N\n",
    "        self.in_directory = in_directory\n",
    "        if out_directory is None:\n",
    "            self.out_directory = self.in_directory\n",
    "        else:\n",
    "            self.out_directory = out_directory\n",
    "        self.splits = splits\n",
    "        self.experiments = []\n",
    "        self.train_percent = train_percent\n",
    "        self.num_nets = num_nets\n",
    "        self.type = exp_type\n",
    "        self.networks = []\n",
    "        self.load_and_save_data()\n",
    "        \n",
    "    def load_and_save_data(self):\n",
    "        for file in os.listdir(self.in_directory):\n",
    "            filename = file[:-4] + '_sparse.npz'\n",
    "            dt = .1 # can change this\n",
    "            if filename not in os.listdir(self.out_directory):\n",
    "                print(f'---------------------- Importing .mat file: {file} ----------------------')\n",
    "                dat = spio.loadmat(os.path.join(self.in_directory, file))\n",
    "                if self.type == 'map':\n",
    "                    xs = []\n",
    "                    StimTimes = dat['StimTimes']\n",
    "                    Cs = np.array(dat['Cs'], dtype='uint32')\n",
    "                    Ts = np.array(dat['Ts'], dtype='uint32')\n",
    "                    foo_s = np.asarray([int(i/dt) for i in StimTimes])\n",
    "                else:\n",
    "                    Cs = dat['data']['Cs']\n",
    "                    Ts = dat['data']['Ts']\n",
    "                    Cs = np.array([a[0] for a in Cs.tolist()[0][0].tolist()], dtype='uint8')\n",
    "                    Ts = np.array([a[0] for a in Ts.tolist()[0][0].tolist()], dtype='uint32')\n",
    "                \n",
    "                Tmax = np.max(Ts)\n",
    "                foo_x = np.asarray([int(i/0.1) for i in Ts])\n",
    "                \n",
    "                ys = []\n",
    "                for i in range(int(Tmax/dt)):\n",
    "                    if i in foo_x:\n",
    "                        # which neurons are firing\n",
    "                        inds = (i*dt<Ts)*(Ts<(i+1)*dt)\n",
    "                        neurons = Cs[inds]\n",
    "                        foo2 = np.zeros(self.N)\n",
    "                        foo2[neurons] = 1\n",
    "                    else:\n",
    "                        foo2 = np.zeros(self.N)\n",
    "                    # is the stimulus firing\n",
    "                    if self.type == 'map':\n",
    "                        if i in foo_s:\n",
    "                            foo2[-1] = 1\n",
    "                        else:\n",
    "                            foo2[-1] = 0\n",
    "                    ys.append(foo2)\n",
    "\n",
    "                ys = np.asarray(ys, dtype='uint8').squeeze()\n",
    "                self.experiments.append(ys)\n",
    "                \n",
    "                y_sparse = csr_matrix(ys, dtype='uint8')\n",
    "                save_npz(os.path.join(self.out_directory, filename), y_sparse)\n",
    "            else:\n",
    "                print(f'---------------------- Loading file: {filename} ----------------------')\n",
    "                ys = load_npz(os.path.join(self.out_directory, filename)).toarray()\n",
    "                self.experiments.append(ys)\n",
    "                \n",
    "    def build_and_train_networks(self):\n",
    "        for i, memories in enumerate(self.experiments):\n",
    "            print(f'---------------------- Conducting experiment: {i} ----------------------')\n",
    "            chunks = []\n",
    "            memories_chunked = self.chunked(memories, self.splits)\n",
    "            for j, memory_chunk in enumerate(memories_chunked):\n",
    "                avg_acc = []\n",
    "                chunked_nets = []\n",
    "                for _ in range(self.num_nets):\n",
    "                    hop = hdn.HopfieldNetMPF(N=self.N)\n",
    "                    rand_memories = np.array([random.choice(memory_chunk) for _ in range(round(len(memory_chunk)*self.train_percent))])\n",
    "                    patterns = hop.store_patterns_using_mpf(rand_memories)\n",
    "                    avg_acc.append(self.get_accuracy(memory_chunk,hop))\n",
    "                    chunked_nets.append(hop)\n",
    "                self.networks.append(chunked_nets)\n",
    "                print(f'Experiment: {i} // Chunk: {j} // Avg Accuracy: {round(np.mean(avg_acc),3)} +/- {round(np.std(avg_acc),3)}')   \n",
    "            print(f'---------------------- Finished experiment: {i} ----------------------')\n",
    "\n",
    "    def chunked(self, iterable, n):\n",
    "        chunksize = int(math.ceil(len(iterable) / n))\n",
    "        return (iterable[i * chunksize:i * chunksize + chunksize]\n",
    "                for i in range(n))\n",
    "            \n",
    "    def getL(self, x, h1, A):\n",
    "        L = np.exp(np.dot(h1.T,x)+A)\n",
    "        if L > 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def get_preds(self, y, hop):\n",
    "        J = hop.J\n",
    "        h = -hop.theta\n",
    "        A = J[-1,-1]\n",
    "        B = h[-1]\n",
    "        # J0 = J[:-1, :-1]\n",
    "        j = J[-1, :-1]\n",
    "        # jT = J[-1, :-1]\n",
    "        # J = J0\n",
    "        h1 = 2*j\n",
    "        # h0 = h\n",
    "        A = A+B\n",
    "        x = y[:-1]\n",
    "        p = self.getL(x, h1, A)\n",
    "        return p\n",
    "    \n",
    "    def get_accuracy(self, memories, hop):\n",
    "        accuracy = 0\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        for k, i in enumerate(memories):\n",
    "            y_preds.append(self.get_preds(i, hop))\n",
    "            y_true.append(i[-1])\n",
    "            if y_preds[k] == y_true[k]:\n",
    "                accuracy += 1\n",
    "        accuracy = accuracy / len(memories)\n",
    "        return round(accuracy*100, 3)\n",
    "    def get_js(self):\n",
    "        \n",
    "        for \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Importing .mat file: Expt1.mat ----------------------\n",
      "---------------------- Conducting experiment: 0 ----------------------\n",
      "Experiment: 0 // Chunk: 0 // Avg Accuracy: 98.678 +/- 0.0\n",
      "Experiment: 0 // Chunk: 1 // Avg Accuracy: 99.152 +/- 0.0\n",
      "Experiment: 0 // Chunk: 2 // Avg Accuracy: 98.685 +/- 0.0\n",
      "---------------------- Finished experiment: 0 ----------------------\n"
     ]
    }
   ],
   "source": [
    "net = ModifiedHopfieldNet(N=61, in_directory='toy_data/', out_directory='new_data/', exp_type='map')\n",
    "net.build_and_train_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train hopfield network on concatenated samples\n",
    "with open('memories.pkl', 'rb') as file:\n",
    "   memories = pickle.load(file)\n",
    "memories = np.array(memories)\n",
    "# hop = hdn.HopfieldNetMPF(N=61)\n",
    "# patterns = hop.store_patterns_using_mpf(memories)\n",
    "# hop.bits_recalled(memories)\n",
    "# with open('hopfieldNet.pkl', 'wb') as file:\n",
    "#    pickle.dump(hop, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy: 98.24199999999999 +/- 0.11822013364905325\n",
      "Avg Accuracy: 98.82 +/- 0.063874877690685\n",
      "Avg Accuracy: 98.502 +/- 0.011661903789692181\n"
     ]
    }
   ],
   "source": [
    "# Divide experiment in three sections and compute accuracy for each half\n",
    "import random\n",
    "beginning = memories[:len(memories)//3, :]\n",
    "middle = memories[len(memories)//3:2*len(memories)//3, :]\n",
    "ending = memories[2*len(memories)//3:, :]\n",
    "data = [beginning, middle, ending]\n",
    "hops = [hdn.HopfieldNetMPF(N=61)]*3\n",
    "for k, i in enumerate(data):\n",
    "    avg_acc = []\n",
    "    for _ in range(5):\n",
    "        hop = hdn.HopfieldNetMPF(N=61)\n",
    "        patterns = hop.store_patterns_using_mpf([random.choice(i) for _ in range(round(len(i)*4/5))])\n",
    "        avg_acc.append(get_accuracy(data[k],hop))\n",
    "    print(f'Avg Accuracy: {round(np.mean(avg_acc),3)} +/- {round(np.std(avg_acc),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.07\n",
      "Accuracy: 98.55\n"
     ]
    }
   ],
   "source": [
    "beginning = memories[:len(memories)//2, :]\n",
    "ending = memories[len(memories)//2:, :]\n",
    "data = [beginning, ending]\n",
    "hops = [hdn.HopfieldNetMPF(N=61), hdn.HopfieldNetMPF(N=61)]\n",
    "acc = []\n",
    "for k, i in enumerate(data):\n",
    "    patterns = hops[k].store_patterns_using_mpf(i)\n",
    "#     print(f'Bits Recalled: {hops[k].bits_recalled(i)}')\n",
    "    acc.append(get_accuracy(data[k],hops[k]))\n",
    "    print(f'Accuracy: {acc[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3332"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "memories = net.experiments[0][:10000, :]\n",
    "\n",
    "import math\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    chunksize = int(math.ceil(len(iterable) / n))\n",
    "    return (iterable[i * chunksize:i * chunksize + chunksize]\n",
    "            for i in range(n))\n",
    "list1 = memories.tolist()\n",
    "len(list(chunked(list1, 3))[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b983275ae514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_true, y_preds)\n",
    "print(precision, recall)\n",
    "print(confusion_matrix(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('hopfieldNet.pkl', 'rb') as file:\n",
    "   hop = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
